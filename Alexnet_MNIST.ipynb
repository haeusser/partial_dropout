{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from random import randint\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set Random-Seeds\n",
    "random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Read Dataset\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dimension = 784\n",
    "output_dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, input_dimension])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, output_dimension])\n",
    "#keep_prob = tf.placeholder(tf.float32)\n",
    "keep_prob_fc1 = tf.placeholder(tf.float32)\n",
    "keep_prob_fc2 = tf.placeholder(tf.float32)\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride_size):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride_size, stride_size, 1], padding='SAME')\n",
    "\n",
    "def max_pool_3x3(x, k_size, stride_size):\n",
    "  return tf.nn.max_pool(x, ksize=[1, k_size, k_size, 1], strides=[1, stride_size, stride_size, 1], padding='VALID')\n",
    "\n",
    "  \n",
    "x_image = tf.reshape(x, [-1,28,28,1])  \n",
    "  \n",
    "# conv1, pool1  \n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 1) + b_conv1)\n",
    "h_pool1 = max_pool_3x3(h_conv1, 2, 2)\n",
    "\n",
    "\n",
    "# conv2, pool2  \n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 1) + b_conv2)\n",
    "h_pool2 = max_pool_3x3(h_conv2, 2, 2)\n",
    "\n",
    "\n",
    "# conv3, pool3  \n",
    "#W_conv3 = weight_variable([3, 3, 192, 384])\n",
    "#b_conv3 = bias_variable([384])\n",
    "\n",
    "#h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3, 1) + b_conv3)\n",
    "\n",
    "\n",
    "# conv4  \n",
    "#W_conv4 = weight_variable([3, 3, 384, 256])\n",
    "#b_conv4 = bias_variable([256])\n",
    "\n",
    "#h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "\n",
    "# conv5, pool5\n",
    "#W_conv5 = weight_variable([3, 3, 256, 256])\n",
    "#b_conv5 = bias_variable([256])\n",
    "\n",
    "#h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "#h_pool5 = max_pool_3x3(h_conv5, 3, 2)\n",
    "\n",
    "\n",
    "# fc1_drop\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool5_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob_fc1)\n",
    "\n",
    "\n",
    "# fc2_drop\n",
    "W_fc2 = weight_variable([1024, 1024])\n",
    "b_fc2 = bias_variable([1024])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob_fc2)\n",
    "\n",
    "\n",
    "# softm\n",
    "W_softm =  weight_variable([1024, 10])\n",
    "b_softm = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc2_drop, W_softm) + b_softm\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test accuracy 0.000000\n",
      "step 1, test accuracy 0.000000\n",
      "step 2, test accuracy 0.000000\n",
      "step 3, test accuracy 0.000000\n",
      "step 4, test accuracy 0.000000\n",
      "step 5, test accuracy 0.000000\n",
      "step 6, test accuracy 0.000000\n",
      "step 7, test accuracy 0.000000\n",
      "step 8, test accuracy 0.000000\n",
      "step 9, test accuracy 0.000000\n",
      "step 10, test accuracy 0.000000\n",
      "step 11, test accuracy 0.000000\n",
      "step 12, test accuracy 0.000000\n",
      "step 13, test accuracy 0.000000\n",
      "step 14, test accuracy 0.000000\n",
      "step 15, test accuracy 0.000000\n",
      "step 16, test accuracy 0.000000\n",
      "step 17, test accuracy 0.000000\n",
      "step 18, test accuracy 0.000000\n",
      "step 19, test accuracy 0.000000\n",
      "step 20, test accuracy 0.000000\n",
      "step 21, test accuracy 0.000000\n",
      "step 22, test accuracy 0.000000\n",
      "step 23, test accuracy 0.000000\n",
      "step 24, test accuracy 0.000000\n",
      "step 25, test accuracy 0.000000\n",
      "step 26, test accuracy 0.000000\n",
      "step 27, test accuracy 0.000000\n",
      "step 28, test accuracy 0.000000\n",
      "step 29, test accuracy 0.000000\n",
      "step 30, test accuracy 0.000000\n",
      "step 31, test accuracy 0.000000\n",
      "step 32, test accuracy 0.000000\n",
      "step 33, test accuracy 0.000000\n",
      "step 34, test accuracy 0.000000\n",
      "step 35, test accuracy 0.000000\n",
      "step 36, test accuracy 0.000000\n",
      "step 37, test accuracy 0.000000\n",
      "step 38, test accuracy 0.000000\n",
      "step 39, test accuracy 0.000000\n",
      "step 40, test accuracy 0.000000\n",
      "step 41, test accuracy 0.000000\n",
      "step 42, test accuracy 0.000000\n",
      "step 43, test accuracy 0.000000\n",
      "step 44, test accuracy 0.000000\n",
      "step 45, test accuracy 0.000000\n",
      "step 46, test accuracy 0.000000\n",
      "step 47, test accuracy 0.000000\n",
      "step 48, test accuracy 0.000000\n",
      "step 49, test accuracy 0.000000\n",
      "step 50, test accuracy 0.000000\n",
      "step 51, test accuracy 0.000000\n",
      "step 52, test accuracy 0.000000\n",
      "step 53, test accuracy 0.000000\n",
      "step 54, test accuracy 0.000000\n",
      "step 55, test accuracy 0.000000\n",
      "step 56, test accuracy 0.000000\n",
      "step 57, test accuracy 0.000000\n",
      "step 58, test accuracy 0.000000\n",
      "step 59, test accuracy 0.000000\n",
      "step 60, test accuracy 0.000000\n",
      "step 61, test accuracy 0.000000\n",
      "step 62, test accuracy 0.000000\n",
      "step 63, test accuracy 0.000000\n",
      "step 64, test accuracy 0.000000\n",
      "step 65, test accuracy 0.000000\n",
      "step 66, test accuracy 0.000000\n",
      "step 67, test accuracy 0.000000\n",
      "step 68, test accuracy 0.000000\n",
      "step 69, test accuracy 0.000000\n",
      "step 70, test accuracy 0.000000\n",
      "step 71, test accuracy 0.000000\n",
      "step 72, test accuracy 0.000000\n",
      "step 73, test accuracy 0.000000\n",
      "step 74, test accuracy 0.000000\n",
      "step 75, test accuracy 0.000000\n",
      "step 76, test accuracy 0.000000\n",
      "step 77, test accuracy 0.000000\n",
      "step 78, test accuracy 0.000000\n",
      "step 79, test accuracy 0.000000\n",
      "step 80, test accuracy 0.000000\n",
      "step 81, test accuracy 0.000000\n",
      "step 82, test accuracy 0.000000\n",
      "step 83, test accuracy 0.000000\n",
      "step 84, test accuracy 0.000000\n",
      "step 85, test accuracy 0.000000\n",
      "step 86, test accuracy 0.000000\n",
      "step 87, test accuracy 0.000000\n",
      "step 88, test accuracy 0.000000\n",
      "step 89, test accuracy 0.000000\n",
      "step 90, test accuracy 0.000000\n",
      "step 91, test accuracy 0.000000\n",
      "step 92, test accuracy 0.000000\n",
      "step 93, test accuracy 0.000000\n",
      "step 94, test accuracy 0.000000\n",
      "step 95, test accuracy 0.000000\n",
      "step 96, test accuracy 0.000000\n",
      "step 97, test accuracy 0.000000\n",
      "step 98, test accuracy 0.000000\n",
      "step 99, test accuracy 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c3f5d1670d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m##test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/stud/tomani/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.pyc\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, fake_data)\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;31m# Start next epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the model \n",
    "\n",
    "##train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(5e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sum_train_accuracy = 0\n",
    "\n",
    "for i in range(2000000):\n",
    "    \n",
    "    batch = mnist.train.next_batch(100)\n",
    "\n",
    "    ##test the model\n",
    "    if i%600 == 0:\n",
    "        sum_test_accuracy = 0\n",
    "        for j in range(100):\n",
    "            batch_test = mnist.test.next_batch(100)\n",
    "            #train_accuracy = accuracy.eval(feed_dict={x:batch_train[0], y_: batch_train[1], keep_prob_fc1: 1.0, keep_prob_fc2: 1.0})\n",
    "            sum_test_accuracy += accuracy.eval(feed_dict={x:batch_test[0], y_: batch_test[1], keep_prob_fc1: 1.0, keep_prob_fc2: 1.0})\n",
    "        overall_test_accuracy = (sum_test_accuracy/100.)\n",
    "        print(\"step %d, test accuracy %f\"%((i/600.), overall_test_accuracy))\n",
    "\t\n",
    "    ##Define at which layer dropout is applied\n",
    "    prob_fc1 = 1.0\n",
    "    prob_fc2 = 1.0\n",
    "    rand_num = random.randint(1, 2)\n",
    "    if rand_num == 1:\n",
    "        prob_fc1 = 0.5\n",
    "    elif rand_num == 2:\n",
    "        prob_fc2 = 0.5\n",
    "    #print (prob_fc1)\n",
    "    #print (prob_fc2)\t\n",
    "    \n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob_fc1: prob_fc1, keep_prob_fc2: prob_fc2}) \n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob_fc1: 1.0, keep_prob_fc2: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
